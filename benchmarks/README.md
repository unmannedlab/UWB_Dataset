# Yolov5 + Deep Sort with PyTorch

forked from {https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch} and made changes based on our own dataset. 

## Introduction

This repository contains a two-stage-tracker. The detections generated by [YOLOv5](https://github.com/ultralytics/yolov5), a family of object detection architectures and models pretrained on the COCO dataset, are passed to a [Deep Sort algorithm](https://github.com/ZQPei/deep_sort_pytorch) which tracks the objects. It can track any object that your Yolov5 model was trained to detect.


## Before you run the tracker

1. Clone the repository:

`git clone https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch.git`

2. Make sure that you fulfill all the requirements: Python 3.8 or later with all [requirements.txt](https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch/blob/master/requirements.txt) dependencies installed, including torch>=1.7. To install, run:

`pip install -r requirements.txt`

## Tracking sources

Tracking can be run on most video formats

```bash
$ python track.py --source 0  # webcam
                           img.jpg  # image
                           vid.mp4  # video
                           path/  # directory
                           path/*.jpg  # glob
                           'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                           'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream
```


## Select object detection and ReID model

### Yolov5

There is a clear trade-off between model inference speed and accuracy. In order to make it possible to fulfill your inference speed/accuracy needs
you can select a Yolov5 family model for automatic download

```bash


$ python track.py --source 0 --yolo_model yolov5n.pt --img 640
                                          yolov5s.pt
                                          yolov5m.pt
                                          yolov5l.pt 
                                          yolov5x.pt --img 1280
                                          ...
```

### DeepSort

Choose a ReID model based on your needs from this ReID [model zoo](https://kaiyangzhou.github.io/deep-person-reid/MODEL_ZOO)

```bash


$ python track.py --source 0 --deep_sort_model osnet_x1_0
                                               nasnsetmobile
                                               resnext101_32x8d
                                               ...
```

## Filter tracked classes

By default the tracker tracks all MS COCO classes.

If you only want to track persons I recommend you to get [these weights](https://drive.google.com/file/d/1gglIwqxaH2iTvy6lZlXuAcMpd_U0GCUb/view?usp=sharing) for increased performance

```bash
python3 track.py --source 0 --yolo_model yolov5/weights/crowdhuman_yolov5m.pt --classes 0  # tracks persons, only
```

If you want to track a subset of the MS COCO classes, add their corresponding index after the classes flag

```bash
python3 track.py --source 0 --yolo_model yolov5s.pt --classes 16 17  # tracks cats and dogs, only
```

[Here](https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/) is a list of all the possible objects that a Yolov5 model trained on MS COCO can detect. Notice that the indexing for the classes in this repo starts at zero.


## MOT compliant results

Can be saved to your experiment folder `track/expN` by 

```bash
python3 track.py --source ... --save-txt
```

## Generate tracking results for each sequence in our dataset
```bash
python3 track.py --source <path_to_output.mp4> --save-txt --save-vid --evaluate --yolo_model yolov5/weights/crowdhuman_yolov5m.pt --classes 0 --imgsz 728 1296
```
Note: remember to change the path to output.mp4 video, for example `~/Document/output.mp4`

## Moving data from experiment folder to MOT16 folder
```bash
mv ~/benchmarks/runs/track/exp/* \
   ~/benchmarks/MOT16_eval/TrackEval/data/trackers/mot_challenge/MOT16-train/ch_yolov5m_deep_sort/data/
```
## Run the evaluation on our dataset
```bash
python ~/benchmarks/MOT16_eval/TrackEval/scripts/run_mot_challenge.py --BENCHMARK MOT16 \
 --TRACKERS_TO_EVAL ch_yolov5m_deep_sort --SPLIT_TO_EVAL train --METRICS CLEAR Identity HOTA \
 --USE_PARALLEL False --NUM_PARALLEL_CORES 4
```

## Cite

If you find this repo useful in your research, please also cite:

```latex
@misc{yolov5deepsort2020,
    title={Real-time multi-object tracker using YOLOv5 and deep sort},
    author={Mikel Brostr√∂m},
    howpublished = {\url{https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch}},
    year={2020}
}
```
